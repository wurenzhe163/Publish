{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e82e62-ea68-4442-8575-c13a52492d1b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap\n",
    "import numpy as np\n",
    "import math\n",
    "import time \n",
    "import traceback\n",
    "import sys,os\n",
    "# Check if you are in a Jupyter notebook and skip os.chdir() for Jupyter\n",
    "if '__file__' in globals():\n",
    "    script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    os.chdir(script_dir)\n",
    "\n",
    "from tqdm import trange\n",
    "from Func.Basic_tools import *\n",
    "from Func.New_Correct import *\n",
    "from Func.Correct_filter import *\n",
    "from Func.S2_filter import *\n",
    "\n",
    "geemap.set_proxy(port=10809)\n",
    "ee.Authenticate()\n",
    "ee.Initialize()\n",
    "print('geemap version = {}\\ngeemap path = {}'.format(geemap.__version__,geemap.__path__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28954e6-a343-4da5-850d-45e0bcfa12f9",
   "metadata": {},
   "source": [
    "# Geometric Distortion Correction Functions\n",
    "\n",
    "## `CalDitor` Function\n",
    "\n",
    "**Purpose:** This function performs geometric distortion correction for satellite imagery, specifically for ascending and descending orbits.\n",
    "\n",
    "**Parameters:**\n",
    "- **s1_ascending:** Sentinel-1 image in ascending orbit.\n",
    "- **s1_descending:** Sentinel-1 image in descending orbit.\n",
    "- **Bands_:** List of bands to process, default is `['VV_gamma0_flatDB', 'VH_gamma0_flatDB']`.\n",
    "- **Origin_Method:** Method for initial distortion calculation, default is `'RS'`.\n",
    "- **Method:** Specifies the correction method, either `'1'` or `'2'`.\n",
    "- **AOI_buffer:** Area of Interest buffer for processing.\n",
    "- **Origin_scale:** Scale for the original image, default is `10`.\n",
    "- **projScale:** Projection scale, default is `30`.\n",
    "\n",
    "**Functionality:**\n",
    "1. **Slope Correction:** Applies a slope correction to the images using `my_slope_correction`.\n",
    "2. **Z-score Normalization:** Normalizes the images to match their median values, reducing the impact of different backscatter values.\n",
    "3. **Geometric Distortion Detection:**\n",
    "   - Generates auxiliary lines for both ascending and descending images.\n",
    "   - Uses `Line_Correct` or `Line_Correct2` based on the specified `Method` to detect layover and shadow distortions.\n",
    "4. **Output Preparation:** Renames the resulting distortion bands to avoid errors.\n",
    "\n",
    "**Returns:**\n",
    "- Distortion masks for layover and shadow for both orbits.\n",
    "- Auxiliary line data for both orbits.\n",
    "- Volume metric dictionary and synthesis data.\n",
    "\n",
    "---\n",
    "\n",
    "## `Combin_AB` Function\n",
    "\n",
    "**Purpose:** Combines the distortion masks from ascending and descending orbits to create a comprehensive distortion map and correct the imagery accordingly.\n",
    "\n",
    "**Parameters:**\n",
    "- **LeftLayoverA, RightLayoverA, ShadowA:** Distortion masks for ascending orbit.\n",
    "- **LeftLayoverD, RightLayoverD, ShadowD:** Distortion masks for descending orbit.\n",
    "- **volumetric_dict:** Dictionary containing processed images and parameters.\n",
    "- **AOI_buffer:** Area of Interest buffer for processing.\n",
    "- **restrict:** Boolean flag to choose between strict or lenient correction mode.\n",
    "\n",
    "**Functionality:**\n",
    "1. **Mask Calculation:**\n",
    "   - Calculates masks for each type of distortion (left layover, right layover, shadow) for both orbits.\n",
    "   - Combines these masks to create a total distortion map.\n",
    "\n",
    "2. **Distortion Correction:**\n",
    "   - **Strict Mode:** If both orbits show distortion, the area is masked out.\n",
    "   - **Lenient Mode:** Uses the opposite orbit's image to replace distorted areas, if possible.\n",
    "\n",
    "3. **Image Synthesis:**\n",
    "   - Generates mean, max, and min composite images from corrected ascending and descending data.\n",
    "\n",
    "**Returns:**\n",
    "- `s1_unit_mean_`: Mean composite image.\n",
    "- `s1_unit_max_`: Maximum composite image.\n",
    "- `s1_unit_min_`: Minimum composite image.\n",
    "- `DistorDict`: A dictionary containing all distortion masks and the combined distortion mask.\n",
    "\n",
    "---\n",
    "\n",
    "**Notes:**\n",
    "- The functions use Earth Engine (`ee`) for image processing, which implies they are designed to work within Google Earth Engine's environment.\n",
    "- The `Method` parameter in `CalDitor` affects how geometric distortions are detected and corrected, with different algorithms potentially providing different results or performance.\n",
    "- The `restrict` parameter in `Combin_AB` allows users to choose between a strict correction where areas with distortions in both orbits are excluded, or a lenient approach where data from the opposite orbit is used to fill in gaps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2495e1f6-17e9-46cd-9960-5ea762426e1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def CalDitor(s1_ascending, s1_descending, Bands_=['VV_gamma0_flatDB', 'VH_gamma0_flatDB'], Origin_Method='RS', Method='1', \n",
    "             AOI_buffer=None, Origin_scale=10, projScale=30):\n",
    "    \n",
    "    # Apply slope correction\n",
    "    volumetric_dict = my_slope_correction(s1_ascending, s1_descending, AOI_buffer, DEMNASA, Model, Origin_scale, DistorMethed=Origin_Method)\n",
    "\n",
    "    # Z-score normalization and histogram matching\n",
    "    Ascending_Img = volumetric_dict['ASCENDING'].select(Bands_)\n",
    "    Descending_Img = volumetric_dict['DESCENDING'].select(Bands_)\n",
    "    \n",
    "    A_median = Ascending_Img.reduceRegion(**{\n",
    "        'reducer': ee.Reducer.median(),\n",
    "        'geometry': AOI_buffer\n",
    "    }).toArray()\n",
    "    D_median = Descending_Img.reduceRegion(**{\n",
    "        'reducer': ee.Reducer.median(),\n",
    "        'geometry': AOI_buffer\n",
    "    }).toArray()\n",
    "    \n",
    "    Ascending_Img = Ascending_Img.subtract(A_median.subtract(D_median).getInfo())\n",
    "    volumetric_dict['ASCENDING'] = replaceBands(volumetric_dict['ASCENDING'], Ascending_Img)\n",
    "\n",
    "    # Detect geometric distortions based on linear relationships\n",
    "    Templist_A = AuxiliaryLine2Point(volumetric_dict['ASCENDING'], volumetric_dict['ASCENDING_parms']['s1_azimuth_across'],\n",
    "                                     volumetric_dict['ASCENDING_parms']['coordinates_dict'],\n",
    "                                     volumetric_dict['ASCENDING_parms']['Auxiliarylines'],\n",
    "                                     projScale)\n",
    "\n",
    "    Templist_D = AuxiliaryLine2Point(volumetric_dict['DESCENDING'], volumetric_dict['DESCENDING_parms']['s1_azimuth_across'],\n",
    "                                     volumetric_dict['DESCENDING_parms']['coordinates_dict'],\n",
    "                                     volumetric_dict['DESCENDING_parms']['Auxiliarylines'],\n",
    "                                     projScale)\n",
    "\n",
    "    if Method == '1':\n",
    "        LeftLayoverA, RightLayoverA, ShadowA = Line_Correct(volumetric_dict['ASCENDING'], AOI_buffer, Templist_A, 'ASCENDING',\n",
    "                                                           volumetric_dict['ASCENDING_parms']['proj'], projScale, Origin_scale,\n",
    "                                                           filt_distance=False, save_peak=False, line_points_connect=True, Peak_Llay=True, Peak_shdow=True, Peak_Rlay=True)\n",
    "        LeftLayoverD, RightLayoverD, ShadowD = Line_Correct(volumetric_dict['DESCENDING'], AOI_buffer, Templist_D, 'DESCENDING',\n",
    "                                                           volumetric_dict['DESCENDING_parms']['proj'], projScale, Origin_scale,\n",
    "                                                           filt_distance=False, save_peak=False, line_points_connect=True, Peak_Llay=True, Peak_shdow=True, Peak_Rlay=True)\n",
    "    elif Method == '2':\n",
    "        LeftLayoverA, RightLayoverA, ShadowA = Line_Correct2(volumetric_dict['ASCENDING'], AOI_buffer, Templist_A, 'ASCENDING',\n",
    "                                                             volumetric_dict['ASCENDING_parms']['proj'], projScale, Origin_scale)\n",
    "        LeftLayoverD, RightLayoverD, ShadowD = Line_Correct2(volumetric_dict['DESCENDING'], AOI_buffer, Templist_D, 'DESCENDING',\n",
    "                                                             volumetric_dict['DESCENDING_parms']['proj'], projScale, Origin_scale)\n",
    "    else:\n",
    "        print(f'Method = {Method}')\n",
    "        raise Exception('Method should be either 1 or 2')\n",
    "\n",
    "    # Rename bands to avoid constant error\n",
    "    LeftLayoverA = LeftLayoverA.rename('LeftLayoverA')\n",
    "    RightLayoverA = RightLayoverA.rename('RightLayoverA')\n",
    "    ShadowA = ShadowA.rename('ShadowA')\n",
    "    LeftLayoverD = LeftLayoverD.rename('LeftLayoverD')\n",
    "    RightLayoverD = RightLayoverD.rename('RightLayoverD')\n",
    "    ShadowD = ShadowD.rename('ShadowD')\n",
    "\n",
    "    return LeftLayoverA, RightLayoverA, ShadowA, Templist_A, LeftLayoverD, RightLayoverD, ShadowD, Templist_D, volumetric_dict, synthesis\n",
    "\n",
    "def Combin_AB(LeftLayoverA, RightLayoverA, ShadowA, LeftLayoverD, RightLayoverD, ShadowD, \n",
    "              volumetric_dict, AOI_buffer=None, restrict=False):\n",
    "    \n",
    "    def Cal_mask(LeftLayover, RightLayover, Shadow, AOI_buffer):\n",
    "        # Check if images are empty\n",
    "        left_empty = LeftLayover.bandNames().length().eq(0)\n",
    "        right_empty = RightLayover.bandNames().length().eq(0)\n",
    "        shadow_empty = Shadow.bandNames().length().eq(0)\n",
    "\n",
    "        # Combine non-empty images\n",
    "        result = ee.Image(ee.Algorithms.If(left_empty, ee.Image(), LeftLayover))\n",
    "        result = ee.Image(ee.Algorithms.If(right_empty, result, result.Or(RightLayover)))\n",
    "        result = ee.Image(ee.Algorithms.If(shadow_empty, result, result.Or(Shadow)))\n",
    "        return result.clip(AOI_buffer)\n",
    "\n",
    "    LeftLayoverA_, RightLayoverA_, ShadowA_ = LeftLayoverA.mask().clip(AOI_buffer), RightLayoverA.mask().clip(AOI_buffer), ShadowA.mask().clip(AOI_buffer)\n",
    "    LeftLayoverD_, RightLayoverD_, ShadowD_ = LeftLayoverD.mask().clip(AOI_buffer), RightLayoverD.mask().clip(AOI_buffer), ShadowD.mask().clip(AOI_buffer)\n",
    "\n",
    "    A_mask_ = Cal_mask(LeftLayoverA_, RightLayoverA_, ShadowA_, AOI_buffer)\n",
    "    D_mask_ = Cal_mask(LeftLayoverD_, RightLayoverD_, ShadowD_, AOI_buffer)\n",
    "    All_distor = A_mask_.And(D_mask_)\n",
    "\n",
    "    DistorDict = {\n",
    "        'LeftLayoverA': LeftLayoverA, 'RightLayoverA': RightLayoverA, 'ShadowA': ShadowA, 'A_mask_': A_mask_,\n",
    "        'LeftLayoverD': LeftLayoverD, 'RightLayoverD': RightLayoverD, 'ShadowD': ShadowD, 'D_mask_': D_mask_,\n",
    "        'All_distor': All_distor\n",
    "    }\n",
    "    \n",
    "    # Check if distortions exist\n",
    "    A_empty = A_mask_.bandNames().contains('constant')\n",
    "    A_empty = ee.Number(ee.Algorithms.If(A_empty, 1, 0))\n",
    "    D_empty = D_mask_.bandNames().contains('constant')\n",
    "    D_empty = ee.Number(ee.Algorithms.If(D_empty, 1, 0))\n",
    "\n",
    "    s1_ascending_flat = volumetric_dict['ASCENDING'].select([\"VV_gamma0_flatDB\", \"VH_gamma0_flatDB\"])\n",
    "    s1_descending_flat = volumetric_dict['DESCENDING'].select([\"VV_gamma0_flatDB\", \"VH_gamma0_flatDB\"])\n",
    "    \n",
    "    if restrict:\n",
    "        # Strict mode: If both A and D have distortions, the area is set to empty\n",
    "        s1_ascending_ = ee.Image(ee.Algorithms.If(A_empty, s1_ascending_flat, s1_ascending_flat.updateMask(A_mask_.Not())))\n",
    "        s1_descending_ = ee.Image(ee.Algorithms.If(D_empty, s1_descending_flat, s1_descending_flat.updateMask(D_mask_.Not())))\n",
    "        Combin_AD = ee.ImageCollection([s1_ascending_, s1_descending_])\n",
    "        s1_unit_mean_ = Combin_AD.mean().reproject(volumetric_dict['ASCENDING_parms']['proj']).clip(AOI_buffer)\n",
    "        s1_unit_max_ = Combin_AD.max().reproject(volumetric_dict['ASCENDING_parms']['proj']).clip(AOI_buffer)\n",
    "        s1_unit_min_ = Combin_AD.min().reproject(volumetric_dict['ASCENDING_parms']['proj']).clip(AOI_buffer)\n",
    "    else:\n",
    "        # Lenient mode: If there are distortions, prioritize using the opposite track image for replacement\n",
    "        s1_ascending_ = ee.Image(ee.Algorithms.If(A_empty, ee.Image(), s1_ascending_flat.where(A_mask_, s1_descending_flat)))\n",
    "        s1_descending_ = ee.Image(ee.Algorithms.If(D_empty, ee.Image(), s1_descending_flat.where(D_mask_, s1_ascending_flat)))\n",
    "        Combin_AD = ee.ImageCollection([s1_ascending_, s1_descending_])\n",
    "        s1_unit_mean_ = ee.Image(ee.Algorithms.If(A_empty.Or(D_empty), \n",
    "                                                   s1_ascending_flat.add(s1_descending_flat).divide(2), \n",
    "                                                   Combin_AD.mean())).reproject(volumetric_dict['ASCENDING_parms']['proj'])\n",
    "\n",
    "        s1_unit_max_ = ee.Image(ee.Algorithms.If(A_empty.Or(D_empty),\n",
    "                                                  s1_ascending_flat.max(s1_descending_flat),\n",
    "                                                  Combin_AD.max())).reproject(volumetric_dict['ASCENDING_parms']['proj'])\n",
    "\n",
    "        s1_unit_min_ = ee.Image(ee.Algorithms.If(A_empty.Or(D_empty),\n",
    "                                                  s1_ascending_flat.min(s1_descending_flat),\n",
    "                                                  Combin_AD.min())).reproject(volumetric_dict['ASCENDING_parms']['proj'])\n",
    "    \n",
    "    return s1_unit_mean_, s1_unit_max_, s1_unit_min_, DistorDict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d304668c-8746-4a90-95b7-e4898e1d1139",
   "metadata": {},
   "source": [
    "# Cluster Extraction Function\n",
    "\n",
    "## `Cluster_math` Function\n",
    "\n",
    "**Purpose:** This function performs various clustering algorithms on satellite imagery to extract features or segment the image based on different clustering methods.\n",
    "\n",
    "**Parameters:**\n",
    "- **method:** Clustering method to use. Options include:\n",
    "  - `'Kmean'`: K-means clustering.\n",
    "  - `'SNIC'`: Simple Non-Iterative Clustering.\n",
    "  - `'SNIC_Kmean'`: SNIC followed by K-means.\n",
    "  - `'LVQ'`: Learning Vector Quantization.\n",
    "  - `'Xmeans'`: X-means clustering.\n",
    "  - `'Cobweb'`: Cobweb clustering.\n",
    "  - `'CascadeKMeans'`: Cascade K-means clustering.\n",
    "- **img:** The input Earth Engine image to cluster.\n",
    "- **bands:** List of bands from the image to use for clustering.\n",
    "- **index:** A string identifier for saving results.\n",
    "- **visual:** Boolean, if `True`, displays the clustering results on a map.\n",
    "- **save:** Boolean, if `True`, saves the clustering results as a GeoTIFF file.\n",
    "- **region:** Optional, the region to clip the image to before clustering.\n",
    "- **proj:** Optional, the projection to reproject the image to before clustering.\n",
    "\n",
    "**Functionality:**\n",
    "1. **Image Preparation:**\n",
    "   - Selects specified bands and clips the image to the region.\n",
    "   - Normalizes the image using min-max normalization.\n",
    "\n",
    "2. **Clustering:**\n",
    "   - Applies the clustering method specified by `method`:\n",
    "     - **Kmean:** Standard K-means clustering.\n",
    "     - **SNIC:** Simple Non-Iterative Clustering, with optional reprojection.\n",
    "     - **SNIC_Kmean:** SNIC followed by K-means, with options to include or exclude the original image in the second clustering step.\n",
    "     - **LVQ, Xmeans, Cobweb, CascadeKMeans:** Other clustering algorithms from the `Cluster_extract` module.\n",
    "\n",
    "3. **Visualization:**\n",
    "   - If `visual` is `True`, creates a map centered on the region and adds layers for the original image and clustering results.\n",
    "\n",
    "4. **Saving Results:**\n",
    "   - If `save` is `True`, exports the clustering results as GeoTIFF files.\n",
    "\n",
    "**Returns:**\n",
    "- **Map:** A `geemap.Map` object if `visual` is `True`, otherwise `None`.\n",
    "- **result:** The clustered image. For `'SNIC_Kmean'`, it returns an image with bands from both clustering steps.\n",
    "\n",
    "**Notes:**\n",
    "- The function uses the `Cluster_extract` module from `Func.Extract_algorithm` for clustering algorithms.\n",
    "- `'SNIC_Kmean'` has an additional step where it performs K-means clustering twice, once without and once with the original image data.\n",
    "- The `Geemap_export` function is assumed to be defined elsewhere for exporting images.\n",
    "- The `minmax_norm` function is used for image normalization but not defined here.\n",
    "\n",
    "---\n",
    "\n",
    "**Usage Example:**\n",
    "```python\n",
    "# Example usage of the function\n",
    "img = ee.Image('COPERNICUS/S2_SR/20210101T023659_20210101T024330_T52SDC')\n",
    "bands = ['B4', 'B3', 'B2']\n",
    "region = ee.Geometry.Point([107.76, 27.51]).buffer(10000)\n",
    "result = Cluster_math('Kmean', img, bands, 'example', visual=True, save=True, region=region)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2aed33-ecc0-4425-ba5a-3ee95619e2a3",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from Func.Extract_algorithm import Cluster_extract as Cluster\n",
    "\n",
    "def Cluster_math(method: str, img, bands: list, index: str, visual: bool, save: bool, region=None,proj=None):\n",
    "    '''method ('Kmean','SNIC','SNIC_Kmean','LVQ','Xmeans','Cobweb','CascadeKMeans')'''\n",
    "    img = img.select(bands).clip(region)\n",
    "    img = minmax_norm(img,bands,region,scale=Origin_scale,withbound=False)\n",
    "\n",
    "    if proj:\n",
    "        img = img.reproject(proj)\n",
    "    if method == 'Kmean':\n",
    "        result = Cluster.afn_Kmeans(img, region)\n",
    "    elif method == 'Cobweb':\n",
    "        result = Cluster.afn_Cobweb(img, region)\n",
    "    elif method == 'Xmeans':\n",
    "        result = Cluster.afn_Xmeans(img, region)\n",
    "    elif method == 'LVQ':\n",
    "        result = Cluster.afn_LVQ(img, region)\n",
    "    elif method == 'CascadeKMeans':\n",
    "        result = Cluster.afn_CascadeKMeans(img, region)\n",
    "    elif method == 'SNIC':\n",
    "        result = Cluster.afn_SNIC(img)\n",
    "        result = result.select(result.bandNames().removeAll(['clusters', 'seeds']))\n",
    "        result = result.reproject(proj)\n",
    "    elif method == 'SNIC_Kmean':\n",
    "        result = Cluster.afn_SNIC(img)\n",
    "        # 默认舍弃cluster和seed\n",
    "        result = result.select(result.bandNames().removeAll(['clusters', 'seeds']))\n",
    "        result = result.reproject(proj)\n",
    "        result0 = Cluster.afn_Kmeans(result, region)  # 原始图像不参与\n",
    "        result1 = Cluster.afn_Kmeans(result.addBands(img), region)  # 原始图像参与    .unmask(10)\n",
    "\n",
    "    if visual:\n",
    "        Map = geemap.Map(basemap='HYBRID')  #\n",
    "        Map.centerObject(region, zoom=15)\n",
    "        Map.addLayer(img.select(0), {'min': 0, 'max': 1}, 'Origin')\n",
    "        if method in ['Kmean', 'Cobweb', 'Xmeans', 'LVQ', 'CascadeKMeans']:\n",
    "            Map.addLayer(result.randomVisualizer(), {}, method)\n",
    "        elif method == 'SNIC':\n",
    "            Map.addLayer(result.randomVisualizer(), {}, method)\n",
    "        elif method == 'SNIC_Kmean':\n",
    "            Map.addLayer(result0.randomVisualizer(), {}, 'SNIC_Kmean_NoOrigin')\n",
    "            Map.addLayer(result1.randomVisualizer(), {}, 'SNIC_Kmean_YesOrigin')\n",
    "        else:\n",
    "            print('Please check your method str')\n",
    "    else:\n",
    "        Map = None\n",
    "    if save:\n",
    "        if method == 'SNIC_Kmean':\n",
    "            Geemap_export(filename=index + 'NoOrigin' + method + '.tif', collection=False, image=result0,\n",
    "                          region=region, scale=10)\n",
    "            Geemap_export(filename=index + 'YesOrigin' + method + '.tif', collection=False, image=result1,\n",
    "                          region=region, scale=10)\n",
    "        else:\n",
    "            Geemap_export(filename=index + method + '.tif', collection=False, image=result, region=region, scale=10)\n",
    "        pass\n",
    "    if method == 'SNIC_Kmean':\n",
    "        return Map, result0.addBands(result1)\n",
    "    else:\n",
    "        return Map, result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55e01d5-b880-4414-84b4-133395ec1f65",
   "metadata": {},
   "source": [
    "# Adaptive Thresholding Function\n",
    "\n",
    "## `Bandmath` Function\n",
    "\n",
    "**Purpose:** This function applies adaptive thresholding techniques to a single band of a satellite image to segment it based on different thresholding methods.\n",
    "\n",
    "**Parameters:**\n",
    "- **method:** Thresholding method to use. Options include:\n",
    "  - `'otsu'`: Otsu's method for automatic threshold selection.\n",
    "  - `'minimum'`: Minimum error thresholding.\n",
    "  - `'yen'`: Yen's method for threshold selection.\n",
    "  - `'isodata'`: Iterative self-organizing data analysis technique.\n",
    "- **img:** The input Earth Engine image. Should be a single band image.\n",
    "- **band:** The band name to process.\n",
    "- **index:** A string identifier for saving results.\n",
    "- **visual:** Boolean, if `True`, displays the thresholding results on a map.\n",
    "- **save:** Boolean, if `True`, saves the thresholding results as a GeoTIFF file.\n",
    "- **region:** Optional, the region to clip the image to before thresholding.\n",
    "- **proj:** Optional, the projection to reproject the image to before thresholding.\n",
    "\n",
    "**Functionality:**\n",
    "1. **Image Preparation:**\n",
    "   - Selects the specified band and clips the image to the region.\n",
    "   - Normalizes the image using min-max normalization.\n",
    "   - Reprojects the image to the specified projection if provided.\n",
    "\n",
    "2. **Thresholding:**\n",
    "   - Depending on the method:\n",
    "     - **Otsu:** Calculates the threshold using Otsu's method on the image histogram.\n",
    "     - **Minimum:** Uses the minimum error method to find the optimal threshold.\n",
    "     - **Yen:** Applies Yen's thresholding algorithm.\n",
    "     - **Isodata:** Uses the ISODATA algorithm for threshold selection.\n",
    "   - Applies the threshold to create a binary image.\n",
    "\n",
    "3. **Visualization:**\n",
    "   - If `visual` is `True`, creates a map centered on the region, adds layers for the original image, and the thresholded result.\n",
    "\n",
    "4. **Saving Results:**\n",
    "   - If `save` is `True`, exports the thresholded image as a GeoTIFF file.\n",
    "\n",
    "**Returns:**\n",
    "- **Map:** A `geemap.Map` object if `visual` is `True`, otherwise `None`.\n",
    "- **result:** The thresholded image.\n",
    "\n",
    "**Notes:**\n",
    "- The function uses the `Adaptive_threshold` module from `Func.Extract_algorithm` for thresholding algorithms.\n",
    "- Functions like `get_histogram`, `GetHistAndBoundary`, `minmax_norm`, and `Geemap_export` are assumed to be defined elsewhere or imported from other modules.\n",
    "- The image must be a single band for this function to work correctly.\n",
    "\n",
    "---\n",
    "\n",
    "**Usage Example:**\n",
    "```python\n",
    "# Example usage of the function\n",
    "img = ee.Image('COPERNICUS/S2_SR/20210101T023659_20210101T024330_T52SDC')\n",
    "region = ee.Geometry.Point([107.76, 27.51]).buffer(10000)\n",
    "result = Bandmath('otsu', img, 'B4', 'example', visual=True, save=True, region=region)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9609bccb-af5a-4659-a267-277838295341",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from Func.Extract_algorithm import Adaptive_threshold as Adap\n",
    "\n",
    "def Bandmath(method:str,img,band,index:str,visual:bool,save:bool,region=None,proj=None):\n",
    "    '''\n",
    "    method = ['otsu','minimum','yen','isodata']\n",
    "    img: 仅单波段图像\n",
    "    '''\n",
    "    img = img.select(band).clip(region)\n",
    "    img = minmax_norm(img,band,region,scale=Origin_scale,withbound=False)\n",
    "    img = img.reproject(proj).clip(region)\n",
    "\n",
    "    if method == 'otsu':\n",
    "        histogram = get_histogram(img,region=region,scale=Origin_scale)\n",
    "        Threshould_value = Adap.afn_otsu(histogram)\n",
    "        result = img.select(0).gt(Threshould_value).clip(region)  #\n",
    "        print('Threshould value is {}'.format(Threshould_value.getInfo()))\n",
    "\n",
    "    elif method == 'minimum':\n",
    "        bin_centers, counts,_  = GetHistAndBoundary(img,region,Origin_scale,histNum=1000,y=300)\n",
    "        Threshould_value = Adap.my_threshold_minimum(bin_centers, counts,max_num_iter = 10000)\n",
    "        result = img.gt(Threshould_value).clip(region)\n",
    "        print('Threshould value is {}'.format(Threshould_value))\n",
    "        \n",
    "    elif method == 'yen':\n",
    "        bin_centers, counts,_ = GetHistAndBoundary(img,region,Origin_scale,histNum=1000,y=300)\n",
    "        Threshould_value = Adap.my_threshold_yen(bin_centers, counts)\n",
    "        result = img.gt(Threshould_value).clip(region)\n",
    "        print('Threshould value is {}'.format(Threshould_value))\n",
    "    \n",
    "    elif method == 'isodata':\n",
    "        bin_centers, counts, bucketWidth = GetHistAndBoundary(img,region,Origin_scale,histNum=1000,y=300)\n",
    "        Threshould_value = Adap.my_threshold_isodata(bin_centers, counts,bucketWidth)\n",
    "        result = img.gt(Threshould_value).clip(region)\n",
    "        print('Threshould value is {}'.format(Threshould_value))\n",
    "\n",
    "    if visual:\n",
    "        Map = geemap.Map(basemap='HYBRID') \n",
    "        Map.centerObject(region, zoom=15)\n",
    "        Map.addLayer(img.select(0), {'min': 0, 'max': 1}, 'Origin')\n",
    "        if method in ['otsu','minimum','yen','isodata']:\n",
    "            Map.addLayer(result.randomVisualizer(), {}, method)\n",
    "        else:\n",
    "            print('Wrong visual! Please check your method str')\n",
    "    else:\n",
    "        Map = None\n",
    "\n",
    "    if save:\n",
    "        if method in ['otsu','minimum','yen','isodata']:\n",
    "            Geemap_export(filename=index+method+'.tif',collection=False,\n",
    "                          image=result,region=region,scale=10)\n",
    "        else:\n",
    "            print('Wrong save! Please check your method str')\n",
    "\n",
    "    return Map,result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cac8902-ae34-4c91-bcf2-c889659e67e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Glacial Lake Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc14263-a509-43b2-bd1f-572d8fcb3a64",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preloading Glacial Lake Data\n",
    "Glacial_lake = ee.FeatureCollection('projects/ee-mrwurenzhe/assets/Glacial_lake/Southwest_WangAndChen_mergeGL')\n",
    "\n",
    "# Calculate geometry, centroid, and minimum bounding rectangle\n",
    "Geo_ext = lambda feature: feature.set({\n",
    "    'Geo': feature.geometry(),\n",
    "    'Centroid': feature.geometry().centroid(),\n",
    "    'Rectangle': feature.geometry().bounds()\n",
    "})\n",
    "\n",
    "Centrid_set = lambda feature: feature.setGeometry(feature.geometry().centroid())\n",
    "Rectangle_set = lambda feature: feature.setGeometry(feature.geometry().bounds())\n",
    "Glacial_lake_C = Glacial_lake.map(Geo_ext).map(Centrid_set)  # Add properties, modify geometry, calculate centroid\n",
    "Glacial_lake_R = Glacial_lake.map(Rectangle_set)             # Calculate minimum bounding rectangle\n",
    "\n",
    "# Extract properties as lists\n",
    "Num_list = Glacial_lake.size().getInfo()\n",
    "Glacial_lake_A_GeoList = Glacial_lake.toList(Num_list)\n",
    "Glacial_lake_C_CentriodList = ee.List(Glacial_lake_C.reduceColumns(ee.Reducer.toList(), ['Centroid']).get('list'))\n",
    "Glacial_lake_R_RectangleList = ee.List(Glacial_lake_C.reduceColumns(ee.Reducer.toList(), ['Rectangle']).get('list'))\n",
    "\n",
    "# Determine time range\n",
    "year = '2019'\n",
    "START_DATE = ee.Date(year + '-06-01')\n",
    "END_DATE = ee.Date(year + '-08-30')\n",
    "S2_START_DATE = ee.Date(year + '-06-01')\n",
    "S2_END_DATE = ee.Date(year + '-09-30')\n",
    "TIME_LEN = END_DATE.difference(START_DATE, 'days').abs()\n",
    "MIDDLE_DATE = START_DATE.advance(TIME_LEN.divide(ee.Number(2)).int(), 'days')\n",
    "\n",
    "# DEM Selection\n",
    "DEMSRTM = ee.Image('USGS/SRTMGL1_003')\n",
    "DEM_prj = DEMSRTM.projection()\n",
    "DEMNASA = ee.Image(\"NASA/NASADEM_HGT/001\").select('elevation')\n",
    "DEMALOS = ee.ImageCollection(\"JAXA/ALOS/AW3D30/V3_2\").mosaic().select('DSM').rename('elevation').reproject(DEM_prj)\n",
    "DEMCOPERNICUS = ee.ImageCollection(\"COPERNICUS/DEM/GLO30\").mosaic().select('DEM').rename('elevation').int16().reproject(DEM_prj)\n",
    "\n",
    "# Geometric Distortion Parameters\n",
    "models = ['volume', 'surface', None]  # Terrain correction models\n",
    "Model = models[0]\n",
    "Origin_scale = 10\n",
    "projScale = 30\n",
    "\n",
    "# S2 Cloudless Parameters\n",
    "CLOUD_FILTER = 60         # Filter S2 images with cloud cover greater than the specified percentage\n",
    "CLD_PRB_THRESH = 15       # Threshold for s2cloudless probability [0-100], originally set at 50\n",
    "NIR_DRK_THRESH = 0.15     # Threshold for dark NIR pixels\n",
    "CLD_PRJ_DIST = 1          # Distance to project cloud shadows from clouds\n",
    "BUFFER = 50               # Remove small cloud-shadow patches and dilate remaining pixels by BUFFER\n",
    "\n",
    "# Classification Methods and Parameters\n",
    "from Func.Extract_algorithm import Reprocess, save_parms\n",
    "def make_dir(path):\n",
    "    return path if os.path.exists(path) else os.makedirs(path) or (print(f\"{path} created successfully\"), path)[1]\n",
    "\n",
    "save_dir = make_dir(f'D:\\\\Dataset_and_Demo\\\\temp\\\\{year} supplementary results')\n",
    "os.chdir(save_dir)\n",
    "Methods = ('Kmean', 'SNIC_Kmean', 'Xmeans', 'CascadeKMeans', 'otsu', 'isodata')\n",
    "resultbands = (0, 1)\n",
    "Imgs = ('s1_unit_mean_',)  # 's1_unit_max_', 's1_unit_min_'\n",
    "Bands = (['VV_gamma0_flatDB'], ['VV_gamma0_flatDB', 'VH_gamma0_flatDB'])\n",
    "mode = 'gpd'\n",
    "savenmae = '{}SouthwestGLs'.format(year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9c01ae-24be-47db-8915-1876f0457e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in trange(0, Num_list):\n",
    "    IoU_All = []\n",
    "    Wrong_dataIndex = []\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        AOI_Centriod = ee.Feature.geometry(ee.Feature(Glacial_lake_C_CentriodList.get(i)))\n",
    "        AOI_GLFeature = ee.Feature(Glacial_lake_A_GeoList.get(i))\n",
    "        AOI_GL = AOI_GLFeature.geometry()\n",
    "        AOI_Rectangle = ee.Feature.geometry(ee.Feature(Glacial_lake_R_RectangleList.get(i)))\n",
    "\n",
    "        # Calculate area\n",
    "        # AOI_area = AOI_GL.area().divide(ee.Number(1000*1000)).getInfo()\n",
    "        # AOI_perometer = AOI_GL.perimeter().divide(1000).getInfo()\n",
    "        # circularity = AOI_area*3.1415926*4/AOI_perometer**2\n",
    "        AOI_area = AOI_GLFeature.get('GL_Area_km').getInfo()\n",
    "        circularity = AOI_GLFeature.get('GL_Circula').getInfo()\n",
    "\n",
    "        # Shrink the glacial lake area\n",
    "        AOI_ShrinKbuffer = AOI_GL.buffer(distance=math.log(AOI_area+1,10) * -3000 * circularity)\n",
    "        AOI_ShrinKbuffer_Centroid = AOI_ShrinKbuffer.centroid()\n",
    "\n",
    "        # Check if the shrunk area is empty, otherwise replace with AOI_area\n",
    "        if AOI_ShrinKbuffer.coordinates().getInfo() != []:\n",
    "            FilterBound = AOI_ShrinKbuffer_Centroid\n",
    "        else:\n",
    "            FilterBound = AOI_Centriod\n",
    "\n",
    "        # The boundary should not be too large, otherwise it will affect the local adaptive extraction effect\n",
    "        AOI_buffer = AOI_Rectangle.buffer(distance=math.log(AOI_area+1,5) * 1200 + 100).bounds()\n",
    "\n",
    "        # Load images, apply filtering functions, filter by date, AOI_buffer is only used to check for null values\n",
    "        s1_ascending, s1_descending = load_image_collection(AOI_buffer, START_DATE, END_DATE, MIDDLE_DATE, Filter='RefinedLee', FilterSize=30)\n",
    "\n",
    "        # Use S2cloudless to produce a cloud-free composite image\n",
    "        s2_sr_median = merge_s2_collection(AOI_buffer, START_DATE, END_DATE, CLOUD_FILTER, BUFFER, CLD_PRJ_DIST, CLD_PRB_THRESH, NIR_DRK_THRESH)\n",
    "        \n",
    "        # Check if the image is synthesized\n",
    "        synthesis_a = ee.Image(s1_ascending).get('synthesis').getInfo()\n",
    "        synthesis_d = ee.Image(s1_descending).get('synthesis').getInfo()\n",
    "        if synthesis_a or synthesis_d:\n",
    "            synthesis = 1\n",
    "        else:\n",
    "            synthesis = 0\n",
    "\n",
    "        if synthesis:\n",
    "            print('Image with synthesis')\n",
    "            s1_ascending = s1_ascending.rename(['VV_gamma0_flatDB', 'VH_gamma0_flatDB', 'incAngle'])\n",
    "            s1_descending = s1_descending.rename(['VV_gamma0_flatDB', 'VH_gamma0_flatDB', 'incAngle'])\n",
    "            default_prj = s1_ascending.select(0).projection()\n",
    "            Combin_ad = ee.ImageCollection([s1_ascending, s1_descending])\n",
    "            s1_unit_mean_ = Combin_ad.mean().reproject(default_prj).clip(AOI_buffer)\n",
    "            s1_unit_max_ = Combin_ad.max().reproject(default_prj).clip(AOI_buffer)\n",
    "            s1_unit_min_ = Combin_ad.min().reproject(default_prj).clip(AOI_buffer)\n",
    "            volumetric_dict = {}\n",
    "            volumetric_dict['ASCENDING'] = s1_ascending.clip(AOI_buffer)\n",
    "            volumetric_dict['ASCENDING_parms'] = {'proj': default_prj}\n",
    "            volumetric_dict['DESCENDING'] = s1_descending.clip(AOI_buffer)\n",
    "            volumetric_dict['DESCENDING_parms'] = {'proj': s1_descending.select(0).projection()}\n",
    "        else:\n",
    "            # Geometric distortion detection and merging of ascending and descending images\n",
    "            LeftLayoverA, RightLayoverA, ShadowA, Templist_A, LeftLayoverD, RightLayoverD, ShadowD, Templist_D, volumetric_dict, synthesis = \\\n",
    "                CalDitor(s1_ascending, s1_descending, Bands_=['VV_gamma0_flatDB', 'VH_gamma0_flatDB'], Origin_Method='RS', Method='1',\n",
    "                        AOI_buffer=AOI_buffer, Origin_scale=Origin_scale, projScale=projScale)\n",
    "            \n",
    "            s1_unit_mean_, s1_unit_max_, s1_unit_min_, DistorDict = \\\n",
    "                Combin_AB(LeftLayoverA, RightLayoverA, ShadowA, LeftLayoverD, RightLayoverD, ShadowD, volumetric_dict, AOI_buffer=AOI_buffer)\n",
    "       \n",
    "        if synthesis_a == 0:\n",
    "            a_name, a_date, a_nodata = ee.List([s1_ascending.get('system:index'), s1_ascending.date().format('YYYY-MM-dd'), s1_ascending.get('numNodata')]).getInfo()\n",
    "        else:\n",
    "            a_name = 'None'; a_date = 'None'; a_nodata = 'All_have'\n",
    "\n",
    "        if synthesis_d == 0:\n",
    "            d_name, d_date, d_nodata = ee.List([s1_descending.get('system:index'), s1_descending.date().format('YYYY-MM-dd'), s1_descending.get('numNodata')]).getInfo()\n",
    "        else:\n",
    "            d_name = 'None'; d_date = 'None'; d_nodata = 'All_have'\n",
    "\n",
    "        pd_dict = {'a_name': a_name, 'd_name': d_name, 'a_date': a_date,\n",
    "                   'd_date': d_date, 'a_nodata': a_nodata, 'd_nodata': d_nodata}\n",
    "\n",
    "        K = [1 if Method == 'SNIC_Kmean' else 0 for Method in Methods]\n",
    "\n",
    "        for k, Method in zip(K, Methods):\n",
    "            for img in Imgs:\n",
    "                for Band in Bands:\n",
    "                    Bands = (['VV_gamma0_flatDB'], ['VV_gamma0_flatDB', 'VH_gamma0_flatDB'])\n",
    "\n",
    "                    if Method in ['Kmean', 'SNIC_Kmean', 'LVQ', 'Xmeans', 'CascadeKMeans']:\n",
    "                        if len(Band) == 2:\n",
    "                            Map, result = Cluster_math(method=Method, img=eval(img), bands=Band, index='',\n",
    "                                                        visual=False, save=False, region=AOI_buffer,\n",
    "                                                        proj=volumetric_dict['ASCENDING_parms']['proj'])\n",
    "                        else:\n",
    "                            print('Method 1 {} Band={}, continue'.format(Method, Band))\n",
    "                            continue\n",
    "\n",
    "                    elif Method in ['otsu', 'minimum', 'yen', 'isodata']:\n",
    "                        if len(Band) == 1:\n",
    "                            Map, result = Bandmath(method=Method, img=eval(img), band=Band, index='',\n",
    "                                    visual=False, save=False, region=AOI_buffer,\n",
    "                                    proj=volumetric_dict['ASCENDING_parms']['proj'])\n",
    "                        else:\n",
    "                            print('Method 2 {} Band={}, continue'.format(Method, Band))\n",
    "                            continue\n",
    "                    else:\n",
    "                        print('Wrong method input!')\n",
    "\n",
    "                    for resultband in range(k + 1):\n",
    "\n",
    "                        # Convert classification map to vector, FilterBound can choose AOI_point or FilterBuffer\n",
    "                        Union_ex = Reprocess.image2vector(result, resultband=resultband, GLarea=AOI_area, FilterBound=FilterBound, del_maxcount=False)\n",
    "                        logname = savenmae + f'{i // 100 * 100}_{i // 100 * 100 + 100}.csv'\n",
    "                        shpname = savenmae + f'{i // 100 * 100}_{i // 100 * 100 + 100}.shp'\n",
    "                        # Export csv and shp\n",
    "                        Result_dict = save_parms.write_pd(Union_ex, i, AOI_GL, img, mode=mode, Method=Method, Band=Band, WithOrigin=resultband, pd_dict=pd_dict,\n",
    "                                              Area_real=AOI_area, logname=logname, shapname=shpname, calIoU=True, cal_resultArea=False, returnParms=True)\n",
    "                        IoU_All.append(Result_dict['IoU'])\n",
    "                        print('Write csv and shp, Method={} Img={} Band={}'.format(Method, img, Band))\n",
    "\n",
    "        # When IoU is relatively small, IoU<0.6, download the images\n",
    "        if np.sum(np.array(IoU_All) > 0.6) == 0:\n",
    "                Geemap_export(fileDirname=f'{i:04d}' + '_' + 'Ascending_' + a_name + '.tif', collection=False, image=volumetric_dict['ASCENDING'], region=AOI_buffer, scale=10)\n",
    "                Geemap_export(fileDirname=f'{i:04d}' + '_' + 'Descending_' + d_name + '.tif', collection=False, image=volumetric_dict['DESCENDING'], region=AOI_buffer, scale=10)\n",
    "                Geemap_export(fileDirname=f'{i:04d}' + '_' + 's2a_sr_median' + '.tif', collection=False, image=s2_sr_median, region=AOI_buffer, scale=10)   \n",
    "            \n",
    "                # Export the merged result images\n",
    "                Geemap_export(fileDirname=f'{i:04d}' + '_' + 's1_unit_mean_' + '.tif', collection=False, image=s1_unit_mean_, region=AOI_buffer, scale=10)\n",
    "                Geemap_export(fileDirname=f'{i:04d}' + '_' + 's1_unit_max_' + '.tif', collection=False, image=s1_unit_max_, region=AOI_buffer, scale=10)\n",
    "                Geemap_export(fileDirname=f'{i:04d}' + '_' + 's1_unit_min_' + '.tif', collection=False, image=s1_unit_min_, region=AOI_buffer, scale=10)\n",
    "                \n",
    "                if synthesis != 1:\n",
    "                    # Export geometric distortion images\n",
    "                    DistorA = LeftLayoverA.rename('LeftLayoverA').addBands(RightLayoverA.rename('RightLayoverA')).addBands(ShadowA.rename('ShadowA'))\n",
    "                    if DistorA.bandNames().length().getInfo() != 0:\n",
    "                        Geemap_export(fileDirname=f'{i:04d}' + '_' + 'DistortionA' + a_name + '.tif', image=DistorA, region=AOI_buffer, scale=10)\n",
    "\n",
    "                    DistorD = LeftLayoverD.rename('LeftLayoverD').addBands(RightLayoverD.rename('RightLayoverD')).addBands(ShadowD.rename('ShadowD'))\n",
    "                    if DistorD.bandNames().length().getInfo() != 0:\n",
    "                        Geemap_export(fileDirname=f'{i:04d}' + '_' + 'DistortionD' + d_name + '.tif', image=DistorD, region=AOI_buffer, scale=10) \n",
    "\n",
    "        end_time = time.time()\n",
    "        print('This function ran for %.5f seconds' % (end_time - start_time))\n",
    "    except:\n",
    "        # Record error information\n",
    "        Wrong_dataIndex.append(i)\n",
    "        with open('log.txt', 'a') as f:\n",
    "            f.write('Wrong index = {}\\n'.format(i))\n",
    "            f.write(traceback.format_exc())\n",
    "            f.write('\\n')\n",
    "        print('Error has been logged to log.txt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GEE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
